var k=Object.defineProperty;var L=(n,t,e)=>t in n?k(n,t,{enumerable:!0,configurable:!0,writable:!0,value:e}):n[t]=e;var y=(n,t,e)=>L(n,typeof t!="symbol"?t+"":t,e);function O(n){return typeof n=="object"&&n!==null&&"type"in n&&typeof n.type=="string"&&["START_UPLOAD","PAUSE_UPLOAD","RESUME_UPLOAD","CANCEL_UPLOAD","GET_UPLOAD_STATUS","GET_ACTIVE_UPLOADS","HEARTBEAT"].includes(n.type)}function l(n,t="info",e){u({type:"LOG",contentId:e,message:n,level:t})}function u(n){self.clients.matchAll().then(t=>{t.forEach(e=>e.postMessage(n))})}var T=class extends Error{constructor(t){super(t),this.name=this.constructor.name,typeof Error.captureStackTrace=="function"?Error.captureStackTrace(this,this.constructor):this.stack=new Error(t).stack}},m=class extends T{constructor(e,a,r){super(e);this.code=a;this.details=r}},P=class extends T{constructor(e,a,r){super(e);this.code=a;this.details=r}};var g={PART_SIZE:10485760,MAX_CONCURRENT_UPLOADS:5,SPEED_CALCULATION_WINDOW:5e3,API_BASE_URL:"/api",API_TIMEOUT:18e4,MAX_FILE_SIZE:10737418240,ALLOWED_FILE_TYPES:["video/mp4","video/quicktime","video/x-msvideo"],DATABASE:{NAME:"UploadDB",VERSION:1},SPEED_TRACKING:{MIN_DATA_POINTS:3,MAX_DATA_POINTS:20,UPDATE_INTERVAL:1e3,EMA_WEIGHT:.3},RETRY:{ATTEMPTS:3,DELAY:1e3,MAX_DELAY:3e4,JITTER_FACTOR:.2,STATUS_CODES:[408,429,500,502,503,504],ERROR_TYPES:["NetworkError","TimeoutError","AbortError","UploadError"]},S3_TRANSFER_ACCELERATION:{ENABLED:!0,MIN_SIZE:536870912,DEFAULT_ENDPOINT:"s3-accelerate.amazonaws.com"}};var R=class{constructor(t,e){y(this,"baseUrl");y(this,"timeout");y(this,"accelerationEndpoint",null);this.baseUrl=t,this.timeout=e}async initiateMultipartUpload(t,e,a){let r=this.shouldUseAcceleration(t.size),o=await this.fetchWithRetry(`${this.baseUrl}/upload/multipart/initiate`,{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({fileName:t.name,fileType:a,size:t.size,duration:e,useAcceleration:r})});if(!o.ok)throw new P("Failed to initiate multipart upload");let s=await o.json();return s.accelerationEndpoint&&(this.accelerationEndpoint=s.accelerationEndpoint),s}async getSignedUrl(t,e,a){let r=await this.fetchWithRetry(`${this.baseUrl}/upload/multipart/signed-url`,{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({partNumber:t,uploadId:e,key:a,useAcceleration:!!this.accelerationEndpoint})});if(!r.ok)throw new m("Failed to get signed URL");return(await r.json()).signedUrl}async uploadPart(t,e,a,r,o){let s=await this.getSignedUrl(a,e,t),i=this.transformToAcceleratedUrl(s),d=await this.fetchWithRetry(i,{method:"PUT",body:r,headers:{"Content-Type":"application/octet-stream","Content-Length":r.size.toString()}},g.RETRY.ATTEMPTS,o);if(!d.ok)throw new m(`Failed to upload part ${a}`);let U=d.headers.get("ETag");if(!U)throw new Error(`No ETag received for part ${a}`);return{partNumber:a,eTag:U.replace(/"/g,""),size:r.size}}async completeMultipartUpload(t,e,a,r){let o=await this.fetchWithRetry(`${this.baseUrl}/upload/multipart/complete`,{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({key:t,uploadId:e,contentId:a,parts:r,useAcceleration:!!this.accelerationEndpoint})});if(!o.ok)throw new P("Failed to complete multipart upload");return await o.json()}async cancelUpload(t,e,a){if(!(await this.fetchWithRetry(`${this.baseUrl}/upload/multipart/cancel`,{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({key:t,uploadId:e,contentId:a,useAcceleration:!!this.accelerationEndpoint})})).ok)throw new m("Failed to cancel multipart upload")}async listUploadedParts(t,e){let a=await this.fetchWithRetry(`${this.baseUrl}/upload/multipart/list-parts`,{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({key:t,uploadId:e})});if(!a.ok)throw new m("Failed to list uploaded parts");return(await a.json()).parts}shouldUseAcceleration(t){return g.S3_TRANSFER_ACCELERATION.ENABLED&&t>=g.S3_TRANSFER_ACCELERATION.MIN_SIZE}transformToAcceleratedUrl(t){return this.accelerationEndpoint?t.replace(/\.s3\.([^.]+)\.amazonaws\.com/,`.${this.accelerationEndpoint}`):t}combineAbortSignals(t){let e=new AbortController;return t.forEach(a=>{a&&(a.aborted?e.abort():a.addEventListener("abort",()=>e.abort()))}),e.signal}async fetchWithTimeout(t,e,a){let r=new AbortController,o=this.combineAbortSignals([r.signal,a]),s=setTimeout(()=>r.abort(),this.timeout);try{let i=await fetch(t,{...e,signal:o});return clearTimeout(s),i}catch(i){throw clearTimeout(s),i instanceof DOMException&&i.name==="AbortError"?new m("Request timed out"):i}}async fetchWithRetry(t,e,a=g.RETRY.ATTEMPTS,r){try{return await this.fetchWithTimeout(t,e,r)}catch(o){if(a>0&&o instanceof m)return await new Promise(s=>setTimeout(s,g.RETRY.DELAY)),this.fetchWithRetry(t,e,a-1,r);throw o}}};var p={name:"UploadServiceWorkerDB",version:1,stores:{uploads:"uploads",chunks:"chunks",metadata:"metadata"}},I=class{constructor(){y(this,"dbPromise",null)}openDatabase(){return this.dbPromise?this.dbPromise:(this.dbPromise=new Promise((t,e)=>{let a=indexedDB.open(p.name,p.version);a.onerror=()=>e(a.error),a.onsuccess=()=>t(a.result),a.onupgradeneeded=r=>{let o=r.target.result;o.objectStoreNames.contains(p.stores.uploads)||o.createObjectStore(p.stores.uploads,{keyPath:"id"}),o.objectStoreNames.contains(p.stores.chunks)||o.createObjectStore(p.stores.chunks,{keyPath:"id"}).createIndex("uploadId","uploadId",{unique:!1}),o.objectStoreNames.contains(p.stores.metadata)||o.createObjectStore(p.stores.metadata,{keyPath:"id"})}}),this.dbPromise)}promisifyRequest(t){return new Promise((e,a)=>{t.onsuccess=()=>e(t.result),t.onerror=()=>a(t.error)})}async saveUploadState(t){l(`Saving upload state for contentId: ${t.contentId}`,"info");try{let r=(await this.openDatabase()).transaction([p.stores.uploads],"readwrite").objectStore(p.stores.uploads);await this.promisifyRequest(r.put(t)),l(`Successfully saved upload state for contentId: ${t.contentId}`,"info")}catch(e){let a=e instanceof Error?e.message:"Unknown error";throw l(`Error saving upload state: ${a}`,"error",t.contentId),e}}async loadUploadState(t){l(`Loading upload state for id: ${t}`,"info");try{let r=(await this.openDatabase()).transaction([p.stores.uploads],"readonly").objectStore(p.stores.uploads),o=await this.promisifyRequest(r.get(t));return l(`Successfully loaded upload state for id: ${t}`,"info"),o}catch(e){let a=e instanceof Error?e.message:"Unknown error";throw l(`Error loading upload state: ${a}`,"error",t),e}}async saveChunk(t){try{let r=(await this.openDatabase()).transaction([p.stores.chunks],"readwrite").objectStore(p.stores.chunks);await this.promisifyRequest(r.put(t))}catch(e){throw e}}async loadChunks(t){try{let o=(await this.openDatabase()).transaction([p.stores.chunks],"readonly").objectStore(p.stores.chunks).index("uploadId");return await this.promisifyRequest(o.getAll(t))}catch(e){throw e}}async deleteUploadState(t){try{let r=(await this.openDatabase()).transaction([p.stores.uploads],"readwrite").objectStore(p.stores.uploads);await this.promisifyRequest(r.delete(t))}catch(e){throw e}}async deleteChunks(t){try{let r=(await this.openDatabase()).transaction([p.stores.chunks],"readwrite").objectStore(p.stores.chunks),s=r.index("uploadId").openKeyCursor(IDBKeyRange.only(t));await new Promise((i,d)=>{s.onerror=()=>d(s.error),s.onsuccess=U=>{let f=U.target.result;f?(r.delete(f.primaryKey),f.continue()):i()}})}catch(e){throw e}}async loadAllUploadStates(){try{let a=(await this.openDatabase()).transaction([p.stores.uploads],"readonly").objectStore(p.stores.uploads);return await this.promisifyRequest(a.getAll())}catch(t){throw t}}},c=new I;var h=new Map,M=class{constructor(){y(this,"apiClient");this.apiClient=new R(g.API_BASE_URL,g.API_TIMEOUT)}async loadOngoingUploads(){let t=await c.loadAllUploadStates();for(let e of t)e.status==="in_progress"&&await this.resumeUpload(e)}async handleUpload(t){let e;if(t.type==="RESUME_UPLOAD"?e=await this.getUploadStateForResume(t.contentId):e=await this.initializeNewUpload(t),!e.contentId)throw new Error("Upload state has no contentId");let a=new AbortController;h.set(e.contentId,{state:e,controller:a}),await c.saveUploadState(e),await this.uploadParts(e,a.signal)}async initializeNewUpload(t){let{file:e,duration:a,fileType:r,chunkConfig:o}=t,s=crypto.randomUUID();l(`Starting upload for contentId: ${s}`,"info");let{uploadId:i,key:d,content:U}=await this.apiClient.initiateMultipartUpload(e,a,r);u({type:"INITIATE_UPLOAD_RESPONSE",contentId:s,uploadId:i,key:d});let f=o?.size??g.PART_SIZE,S=o?.concurrent??g.MAX_CONCURRENT_UPLOADS;return{id:U.id,file:e,fileName:e.name,fileSize:e.size,uploadId:i,key:d,progress:0,status:"in_progress",parts:[],startTime:Date.now(),contentId:U.id,partSize:f,maxConcurrentUploads:S}}async getUploadStateForResume(t){let e=await c.loadUploadState(t);if(!e)throw new Error("No upload state found to resume");return l(`Resuming upload with uploadId: ${e.uploadId}`,"info"),e}async uploadParts(t,e){let{file:a,key:r,uploadId:o,contentId:s,partSize:i}=t;if(!s)throw new Error("Upload state has no contentId");let d=Math.ceil(a.size/i);l(`Total parts to upload: ${d}`,"info");let U=await this.getUploadedParts(t),f=new Set(U.map(b=>b.partNumber)),S=U.length;for(let b=1;b<=d;b++){if(f.has(b)){l(`Skipping already uploaded part ${b}`,"info");continue}let C=(b-1)*i,v=Math.min(C+i,a.size),_=a.slice(C,v);try{let w=await this.uploadPart(s,r,o,b,_,e);t.parts.push(w),S++;let D=Math.round(S/d*100);t.progress=D,await c.saveUploadState(t),this.broadcastProgress(s,D,S,t)}catch(w){throw await this.handleUploadError(s,w),w}}await this.completeUpload(t)}async getUploadedParts(t){try{let e=await this.apiClient.listUploadedParts(t.key,t.uploadId);return l(`Retrieved ${e.length} uploaded parts`,"info"),e}catch(e){return l(`Failed to retrieve uploaded parts: ${e.message}`,"error"),[]}}async uploadPart(t,e,a,r,o,s,i=0){try{let d=await this.apiClient.uploadPart(e,a,r,o,s);return u({type:"CHUNK_UPLOADED",contentId:t,partNumber:r,size:o.size}),{partNumber:r,eTag:d.eTag,size:o.size}}catch(d){let U=d instanceof Error?d.message:"Unknown error";if(i<g.RETRY.ATTEMPTS&&d instanceof m&&!(d instanceof DOMException&&d.name==="AbortError")){let f=Math.min(1e3*Math.pow(2,i),3e4);return u({type:"RETRYING_CHUNK",contentId:t,partNumber:r,attempt:i+1,maxAttempts:g.RETRY.ATTEMPTS,error:U,nextAttemptDelay:f}),await new Promise(S=>setTimeout(S,f)),this.uploadPart(t,e,a,r,o,s,i+1)}throw d}}broadcastProgress(t,e,a,r){let o={type:"UPLOAD_PROGRESS",contentId:t,progress:e,uploadedBytes:a*r.partSize,totalBytes:r.fileSize};u(o)}async completeUpload(t){let{contentId:e,key:a,uploadId:r,parts:o,startTime:s,fileSize:i}=t;if(!e)throw new Error("Upload state has no contentId");l(`Completing upload for contentId: ${e}`,"info");let d=await this.apiClient.completeMultipartUpload(a,r,e,o);t.status="completed",t.fileUrl=d.location,await c.saveUploadState(t),u({type:"UPLOAD_COMPLETE",contentId:e,fileUrl:d.location,duration:Date.now()-s,totalBytes:i,averageSpeed:i/(Date.now()-s)}),h.delete(e),l(`Upload completed for contentId: ${e}`,"info")}async handleUploadError(t,e){let a=e instanceof Error?e.message:"Unknown error",r=e instanceof m;u({type:"UPLOAD_ERROR",contentId:t,error:{code:"UPLOAD_FAILED",message:a,retryable:r}});let o=h.get(t);o&&(o.state.status="error",o.state.error=a,await c.saveUploadState(o.state),h.delete(t))}async handlePause(t){let e=h.get(t);e&&(e.controller.abort(),e.state.status="paused",await c.saveUploadState(e.state),u({type:"UPLOAD_PAUSED",contentId:t}),h.delete(t))}async handleResume(t){try{let e=await c.loadUploadState(t);if(!e||e.status!=="paused"){l(`No paused upload found for contentId: ${t}`,"error");return}e.status="in_progress",await c.saveUploadState(e),await this.handleUpload({type:"RESUME_UPLOAD",contentId:t})}catch(e){await this.handleUploadError(t,e)}}async handleCancel(t){let e=h.get(t);if(e){e.controller.abort(),await c.deleteUploadState(t),await c.deleteChunks(e.state.uploadId);try{await this.apiClient.cancelUpload(e.state.key,e.state.uploadId,t),l(`Successfully cancelled upload for contentId: ${t}`,"info")}catch(a){l(`Error cancelling upload for contentId: ${t}: ${a.message}`,"error")}u({type:"UPLOAD_CANCELLED",contentId:t}),h.delete(t)}}async handleGetActiveUploads(){let t=await c.loadAllUploadStates();for(let e of t)(e.status==="in_progress"||e.status==="paused")&&(await this.resumeUpload(e),u({type:"UPLOAD_STATUS",contentId:e.contentId,status:e.status}))}async handleGetUploadStatus(t){let e=await c.loadUploadState(t);e?u({type:"UPLOAD_STATUS",contentId:t,status:e.status}):u({type:"UPLOAD_STATUS",contentId:t,status:"not_found"})}async resumeUpload(t){let e=t.contentId;if(!e)throw new Error("Upload state has no contentId");if(h.has(e))return;let a=new AbortController;h.set(e,{state:t,controller:a}),await this.uploadParts(t,a.signal)}async resumeAllUploads(){let t=await c.loadAllUploadStates();for(let e of t)(e.status==="paused"||e.status==="in_progress")&&await this.resumeUpload(e)}};function A(n,t,e){n.addEventListener(t,e)}var E=new M,x=async n=>{let t=n.data;if(!O(t)){l("Invalid message received","error");return}let e=t,a="contentId"in e?e.contentId:void 0;l(`Received message: ${e.type}`,"info",a);try{switch(e.type){case"START_UPLOAD":await E.handleUpload(e);break;case"PAUSE_UPLOAD":await E.handlePause(e.contentId);break;case"RESUME_UPLOAD":await E.handleResume(e.contentId);break;case"CANCEL_UPLOAD":await E.handleCancel(e.contentId);break;case"GET_UPLOAD_STATUS":await E.handleGetUploadStatus(e.contentId);break;case"GET_ACTIVE_UPLOADS":await E.handleGetActiveUploads();break;case"HEARTBEAT":break;default:l(`Unhandled message type: ${JSON.stringify(e)}`,"warn",a)}}catch(r){let o=r;l(`Error handling message ${e.type}: ${"message"in o?o.message:"Unexpected error"}`,"error",o.contentId)}};A(self,"install",n=>{console.log("Service Worker installing."),n.waitUntil(self.skipWaiting())});A(self,"activate",n=>{console.log("Service Worker activating."),n.waitUntil(E.loadOngoingUploads())});A(self,"online",()=>{E.resumeAllUploads()});A(self,"message",x);
//# sourceMappingURL=upload.worker.js.map
